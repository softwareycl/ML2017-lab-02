{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "#获取数据\n",
    "def get_data(f):\n",
    "    data = load_svmlight_file(f,123)\n",
    "    return data[0], data[1]\n",
    "\n",
    "#定义sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "#NAG\n",
    "def SGD_NAG(x_train, y_train, x_test, y_test, alpha, r, W, b, maxIterations):\n",
    "    m, n = x_test.shape\n",
    "    M, N = x_train.shape\n",
    "    temp = np.ones((x_test.shape[0], 1))\n",
    "    vw = np.zeros((123, 1))\n",
    "    vb = 0\n",
    "    loss = []\n",
    "    L = 0.5 * np.dot(W.transpose(), W)\n",
    "    temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "    L = L + np.dot(temp0.transpose(), temp)\n",
    "    loss.append(L[0, 0]/X_test.shape[0])\n",
    "\n",
    "    for i in range(maxIterations):\n",
    "        #产生随机索引\n",
    "        randIndex = int(random.uniform(0, M-1))\n",
    "        if y_train[randIndex, 0] * (X_train[randIndex, :] * W + b)[0,0] < 1:\n",
    "            #计算梯度\n",
    "            G_w = (W - vw) - C * (X_train[randIndex, :].T * y_train[randIndex, :])\n",
    "            G_b = -C * y_train[randIndex, 0]\n",
    "        else:\n",
    "            G_w = W\n",
    "            G_b = 0\n",
    "        #更新动量\n",
    "        vw = r * vw + alpha * G_w\n",
    "        vb = r * vb + alpha * G_b\n",
    "        #更新参数\n",
    "        W = W - vw\n",
    "        b = b - vb\n",
    "        \n",
    "        L = 0.5 * np.dot(W.transpose(), W)\n",
    "        temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "        L = L + np.dot(temp0.transpose(), temp)\n",
    "        loss.append(L[0, 0]/X_test.shape[0])\n",
    "    return W, b, loss\n",
    "\n",
    "#RMSProp\n",
    "def SGD_RMSProp(x_train, y_train, x_test, y_test, alpha, r, W, b, maxIterations):\n",
    "    m, n = x_test.shape\n",
    "    M, N = x_train.shape\n",
    "    G_w = np.zeros((123, 1))\n",
    "    G_b = 0\n",
    "    temp = np.ones((x_test.shape[0], 1))\n",
    "    loss = []\n",
    "    L = 0.5 * np.dot(W.transpose(), W)\n",
    "    temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "    L = L + np.dot(temp0.transpose(), temp)\n",
    "    loss.append(L[0, 0]/X_test.shape[0])\n",
    "    \n",
    "\n",
    "    for i in range(maxIterations):\n",
    "        #产生随机索引\n",
    "        randIndex = int(random.uniform(0, M-1))\n",
    "        if y_train[randIndex, 0] * (X_train[randIndex, :] * W + b)[0,0] < 1:\n",
    "            #计算梯度\n",
    "            g_w = W - C * (X_train[randIndex, :].T * y_train[randIndex, :])\n",
    "            g_b = -C * y_train[randIndex, 0]\n",
    "        else:\n",
    "            g_w = W\n",
    "            g_b = 0\n",
    "        G_w = r * G_w + (1 - r) * (g_w * g_w)\n",
    "        G_b = r * G_b + (1 - r) * (g_b * g_b)\n",
    "        #更新参数\n",
    "        W = W - (alpha / np.sqrt(G_w + pow(1, -8))) * g_w\n",
    "        b = b - (alpha / math.sqrt(G_b + pow(1, -8))) * g_b\n",
    "        \n",
    "        L = 0.5 * np.dot(W.transpose(), W)\n",
    "        temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "        L = L + np.dot(temp0.transpose(), temp)\n",
    "        loss.append(L[0, 0]/X_test.shape[0])  \n",
    "    return W, b, loss\n",
    "\n",
    "#AdaDelta\n",
    "def SGD_AdaDelta(x_train, y_train, x_test, y_test, r, W, b, maxIterations):\n",
    "    m, n = x_test.shape\n",
    "    M, N = x_train.shape\n",
    "    G_w = np.zeros((123, 1))\n",
    "    t_w = np.zeros((123, 1))\n",
    "    e_w = np.zeros((123, 1))\n",
    "    G_b = 0\n",
    "    t_b = 0\n",
    "    e_b = 0\n",
    "    temp = np.ones((x_test.shape[0], 1))\n",
    "    loss = []\n",
    "    L = 0.5 * np.dot(W.transpose(), W)\n",
    "    temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "    L = L + np.dot(temp0.transpose(), temp)\n",
    "    loss.append(L[0, 0]/X_test.shape[0])\n",
    "\n",
    "    for i in range(maxIterations):\n",
    "        #产生随机索引\n",
    "        randIndex = int(random.uniform(0, M-1))\n",
    "        if y_train[randIndex, 0] * (X_train[randIndex, :] * W + b)[0,0] < 1:\n",
    "            #计算梯度\n",
    "            g_w = W - C * (X_train[randIndex, :].T * y_train[randIndex, :])\n",
    "            g_b = -C * y_train[randIndex, 0]\n",
    "        else:\n",
    "            g_w = W\n",
    "            g_b = 0\n",
    "        G_w = r * G_w + (1 - r) * (g_w * g_w)\n",
    "        e_w = -(np.sqrt(t_w + pow(1, -6)) / np.sqrt(G_w + pow(1, -6))) * g_w\n",
    "        #更新参数\n",
    "        W = W + e_w / 50\n",
    "        t_w = r * t_w + (1 - r) * (e_w * e_w)\n",
    "        G_b = r * G_b + (1 - r) * (g_b * g_b)\n",
    "        e_b = -(np.sqrt(t_b + pow(1, -6)) / np.sqrt(G_b + pow(1, -6))) * g_b\n",
    "        #更新参数\n",
    "        W = W + e_b / 50\n",
    "        t_b = r * t_b + (1 - r) * (e_b * e_b)\n",
    "        \n",
    "        L = 0.5 * np.dot(W.transpose(), W)\n",
    "        temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "        L = L + np.dot(temp0.transpose(), temp)\n",
    "        loss.append(L[0, 0]/X_test.shape[0])  \n",
    "    return W, b, loss\n",
    "\n",
    "#Adam\n",
    "def SGD_Adam(x_train, y_train, x_test, y_test, alpha, r, B, W, b, maxIterations):\n",
    "    m, n = x_test.shape\n",
    "    M, N = x_train.shape\n",
    "    G_w = np.zeros((123, 1))\n",
    "    G_b = 0\n",
    "    temp = np.ones((x_test.shape[0], 1))\n",
    "    mom_w = np.zeros((123, 1))\n",
    "    mom_b = 0\n",
    "    loss = []\n",
    "    a = 0\n",
    "    L = 0.5 * np.dot(W.transpose(), W)\n",
    "    temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "    L = L + np.dot(temp0.transpose(), temp)\n",
    "    loss.append(L[0, 0]/X_test.shape[0])\n",
    "\n",
    "    for i in range(maxIterations):\n",
    "        #产生随机索引\n",
    "        randIndex = int(random.uniform(0, M-1))\n",
    "        if y_train[randIndex, 0] * (X_train[randIndex, :] * W + b)[0,0] < 1:\n",
    "            #计算梯度\n",
    "            g_w = W - C * (X_train[randIndex, :].T * y_train[randIndex, :])\n",
    "            g_b = -C * y_train[randIndex, 0]\n",
    "        else:\n",
    "            g_w = W\n",
    "            g_b = 0\n",
    "        mom_w = B * mom_w + (1 - B) * g_w\n",
    "        mom_b = B * mom_b + (1 - B) * g_b\n",
    "        G_w = r * G_w + (1 - r) * (g_w * g_w)\n",
    "        G_b = r * G_b + (1 - r) * (g_b * g_b)\n",
    "        a = alpha * np.sqrt(1 - pow(r, i+1)) / (1 - pow(B, i+1))\n",
    "        #更新参数\n",
    "        W = W - a * (mom_w / np.sqrt(G_w + pow(1, -8)))\n",
    "        b = b - a * (mom_b / np.sqrt(G_b + pow(1, -8)))\n",
    "        \n",
    "        L = 0.5 * np.dot(W.transpose(), W)\n",
    "        temp0 = (1 - y_test * (X_test * W + b)).clip(0)\n",
    "        L = L + np.dot(temp0.transpose(), temp)\n",
    "        loss.append(L[0, 0]/X_test.shape[0])  \n",
    "    return W, b, loss\n",
    "\n",
    "#获取数据\n",
    "X_train, y_train = get_data('G:\\MLcode\\data\\\\a9a.txt')\n",
    "X_test, y_test = get_data('G:\\MLcode\\data\\\\a9a.t')\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "#随机初始化模型参数\n",
    "W = np.random.rand(123, 1)\n",
    "b = 0\n",
    "C = 0.1\n",
    "\n",
    "NAG_w, NAG_b, NAG_loss= SGD_NAG(X_train, y_train, X_test, y_test, 0.01, 0.9, W, b, 1000)\n",
    "RMSProp_w, RMSProp_b, RMSProp_loss= SGD_RMSProp(X_train, y_train, X_test, y_test, 0.01, 0.9, W, b, 1000)\n",
    "AdaDelta_w, AdaDelta_b, AdaDelta_loss= SGD_AdaDelta(X_train, y_train, X_test, y_test, 0.95, W, b, 1000)\n",
    "Adam_w, Adam_b, Adam_loss= SGD_Adam(X_train, y_train, X_test, y_test, 0.01, 0.999, 0.9, W, b, 1000)\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "a, = plt.plot(NAG_loss, color = 'blue')\n",
    "b, = plt.plot(RMSProp_loss, color = 'red')\n",
    "c, = plt.plot(AdaDelta_loss, color = 'green')\n",
    "d, = plt.plot(Adam_loss, color = 'black')\n",
    "plt.legend(handles = [a, b, c, d], labels = ['NAG_loss', 'RMSProp_loss', 'AdaDelta_loss', 'Adam_loss'], loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
